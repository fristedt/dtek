1.1
30 bitar, eftersom 1 Gbyte = 2^30 byte.

1.2
Storlek: 32 kbyte.
Blockstorlek: 32 byte.
Associativitet: 1, eftersom cache-minnet är direktmappat.
Rutstorlek = Storlek.
Antalet bitar som inte används till tag är 15 bitar eftersom 32 kbyte = 2^15 byte.
Byte-offset: 5 bitar, eftersom 32 byte = 2^5 byte.
Index: 10 bitar, eftersom 15 - 5 = 10.
Antalet rader: 1024, eftersom vårt index är 10 och 2^10 = 1024.
Resterande bitar går till taggen; 32 - 10 - 5  = 17.

---------------------------------------------------------
|V|Tag                         |Index       |Byte-offset|
| |17 bitar                    |10 bitar    |5 bitar    |
---------------------------------------------------------

1.3
Storlek: 64 byte.
Blockstorlek: 8 byte.
Associativitet: 1.
Rutstorlek = Storlek.
Antalet bitar som inte används till tag är 6 eftersom 64 byte = 2^6 byte.
Byte-offset: 3 bitar, eftersom 8 byte = 2^3 byte.
Index: 3 bitar, eftersom 6 - 3 = 3.
Antalet rader: 8.
Tag: 32 - 6 = 26 bitar.

---------------------------------------------------------
|V|Tag                         |Index       |Byte-offset| x 8
| |26 bitar                    |3 bitar     |3 bitar    |
---------------------------------------------------------

1.4
Varje rad i minnesmatrisen innehåller 1 validbit, 25 bitar för adressetiketten,
3 bitar för index och 3 bitar för byte-offset. 

Validbiten används för att kontrollera om raden innehåller korrekt information.
Indexbitarna används för att peka ut 1 av 8 rader i cacheminnet.
Byte-offsetbitarna används för att peka ut 1 av 8 byte i raden.
Tag används för att kontrollera att det som är skrivet på den valda raden
verkligen motsvarar det sökta värdet i minnet.

1.5
Antalet bitar som inte används till tag kommer att behova ökas, eftersom vi nu
kommer behova 8 bitar för att peka ut en given byte i cachen ty 256 byte = 2^8
byte. Byte-offset lär bli oförändrad eftersom blockstorleken är orörd. Antalet
indexbitar kommer behöva ökas till 5 eftersom 8 (antalet icke-tagbitar) - 3
(byte-offset bitar) = 5. Det innebär att antalet rader kommer bli 2^5 = 32. Vårt
tagfält kommer att använda resterande bitar; 32 - 8 = 24.

---------------------------------------------------------
|V|Tag                         |Index       |Byte-offset| x 32
| |24 bitar                    |5 bitar     |3 bitar    |
---------------------------------------------------------

1.6
Antalet byte-offset bitar blir 5 eftersom 32 byte = 2^5 byte. Antalet
indexbitar förändras inte eftersom vi inte har några nya rader. Resterande bitar
går till taggen.

---------------------------------------------------------
|V|Tag                         |Index       |Byte-offset| x 8
| |24 bitar                    |3 bitar     |5 bitar    |
---------------------------------------------------------

1.7
Vi kommer få 4 rutor som delar på den totala storleken. Varje ruta kommer däför
rymma 64 / 4 = 16 byte. Antalet icke-tagbitar kommer att bli 4, eftersom varje
ruta kommer rymma 16 olika byte och vi vill kunna peka ut samtliga. Eftersom vi
fortfarande har blockstorlek 8 behöver vi fortfarande 3 bitar till byte-offset.
Därför måste antalet indexbitar bli 1. Antalet bitar till taggen kommer att bli
32 - 4 = 28 bitar. Antalet rader kommer bli 2^1 = 2.

-----------------------------------  -----------------------------------
|V|Tag      |Index    |Byte-offset|  |V|Tag      |Index    |Byte-offset| x 2
| |28 bitar |1 bitar  |3 bitar    |  | |28 bitar |1 bitar  |3 bitar    |
-----------------------------------  -----------------------------------

================================================================================

2.1
Instruktionscacheminnet.

2.2
Instruktionscacheminnet.

2.3
För att få mätvärden som är så bra som möjligt bör du räkna ut vilket
cacheminne som har flest missar multiplicerat med antalet klockcykler en miss
orsakar. Detta bör ge den totala tiden som cachemissar orsakar. Det minne med
det högsta värdet bör styra inställningen av miss penalty.

2.4
Du behöver aldrigt skriva till instruktionscacheminnet eftersom när programmet
är kompilerat och startat kommer instruktionerna inte ändras. Ett självklart
undantag till detta är självmodifierande kod, men det används inte tillräckligt
ofta för att justifiera speciella åtgärder vid designen av cacheminnet.

================================================================================

3
Nummer 3: 5553 / 283 ~= 19.62
Nummer 4: 7508 / 283 ~= 26.53

3.1
Instruktioner till simulatorn är 32 bitar = 4 byte. Om cachen är 64 byte
kommer alltså 16 instruktioner rymmars i cachen. Vi vet också att vår loop
kräver 18 instruktioner. Den ryms alltså inte i cachen och det är troligtvis
därför vi får så låg hit rate.

3.2
Nummer 2 och nummer 5. Nummer 5 har lägre körtid än nummer 2, men eftersom deras
hit rate i instruktionscacheminnet är samma måste minskningen av körtid komma
från andra håll.

3.3
Eftersom hela loopen ryms redan då instruktionscachen har storlek 4 * 18 = 72
byte så ger ytterligare storleksökningar ingen förbättrad hit rate. 

================================================================================

4.1
Nej, eftersom samma instruktion inte utförs flera gånger.

4.2
Ja, programmet har bra rumslokalitet eftersom varje instruktion ligger precis
efter den föregående i minnet. Det innebär att när cacheminnet hämtar ett block
från minnet kommer cachen att få flera cacheträffar som följd.

4.3
När första instruktionen hämtas kommer det givetvis att bli en cachemiss. Då
hämtas ett block med storlek 8 byte. 8 byte rymmer två instruktioner. Nästa
instruktion som hämtas kommer därför att finnas i cachen. Efter det blir det
miss igen eftersom endast två instruktioner hämtades. Programmets hit rate bör
därför bli 50%.

================================================================================

5.1
Kolumnindex.

5.2
Instruktionscachen har en så hög hit rate eftersom den största delen av
programmet består av loopar; programmet visar hög tidslokalitet för
instruktioncachen. Datacachen har en så låg hit rate eftersom vi inte använder
samma adress i minnet varje iteration; dålig tidslokalititet. 

5.3
Instruktionscachen har en så hög hit rate eftersom nästan hela programmet består
av loopar. Strcpy hade också loopar men inte till samma grad som matris.

5.4
Eftersom simulatorn inte kan hantera olika accesstider för instruktioncachen
och datacachen måste vi anpassa vår access time efter den cache som har flest
missar. Eftersom instruktioncachen har en hit rate på 100% och datacachen har en
hit rate på 1% måste vi givetvis ställa access time efter vår datacache.

Datacachen har en blockstorlek på 2 ord. Att läsa det första ordet kommer att ta
3 processorklockcykler. Det andra ordet kommer att ta 1 processorklockcykel.
Enligt antaganden i labbinstruktionerna så arbetar vi med en processor med
klockfrekvens 2GHz och ett primärminne med 2MHz. Alltså arbetar processorn 10
gånger snabbare än primärminnet. Den totala tiden det kommer ta att läsa 2 ord
blir därför 30+10 = 40 processorklockcykler.

Medeltiden för att läsa ett ord till data cachen blir därför 40 / 2 = 20
processorklockcykler. Därför är vår access time 20.

5.5
Blockstorlek: 8 byte.
Byte-offset: 3 bitar.
Antal icke-tagbitar: Varierar från 6 till 12 bitar.
Index: Varierar från 3 till 9 bitar.
Rader: Varierar från 2^3 till 2^9, alltså 8 till 512.

Storlek    | 64 | 128 | 256 | 512 | 1024 | 2048 | 4096 |
Indexbitar |  3 |   4 |   5 |   6 |    7 |    8 |    9 |

------------------------------------
|Tag        |Index    |Byte-offset | x 8 - 512
|20-26 bitar|3-9 bitar|3 bitar     |   
------------------------------------

Varje block rymmer 2 heltal.

Antag att a[0][0] ligger på minnesplats 0. Adresserna nedan är trunkerade till
endast icke-tag bitarna.

Cachestorlekar 64 till 1024 byte.
1. Adress: ... 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0
2. Adress: ... 0100 0000 0000, Läs   b[0][0]   MISS, hämta block till rad 0
3. Adress: ... 1000 0000 0000, Skriv res[0][0] MISS, hämta block till rad 0
4. Adress: ... 0000 0000 0100, Läs   a[1][0]   MISS, hämta block till rad 0
5. Adress: ... 0100 0000 0100, Läs   b[1][0]   MISS, hämta block till rad 0
6. Adress: ... 1000 0000 0100, Skriv res[1][0] MISS, hämta block till rad 0
7. Adress: ... 0000 0000 1000, Läs   a[2][0]   MISS, hämta block till rad 1
8. Adress: ... 0100 0000 1000, Läs   b[2][0]   MISS, hämta block till rad 1
9. Adress: ... 1000 0000 1000, Skriv res[2][0] MISS, hämta block till rad 1
10. ...

Vi ser i tabellen ovan att a, b, och res använder minnesrymder vars adresser
har en differens på 1024 bitar. Vi vet också att vi läser eller skriver från
minnet i ordningen a -> b -> res -> a. Det innebär att för alla cacheminnen med
en storlek under 2048 byte så kommer varje operation att skriva över den
föregående blockhämtningen i cachen, eftersom a[i][j] kommer dela index med
b[i][j] och res[i][j]. 

Cachestorlek 2056 byte.
1.  Adress: ... 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0
2.  Adress: ... 0100 0000 0000, Läs   b[0][0]   MISS, hämta block till rad 128
3.  Adress: ... 1000 0000 0000, Skriv res[0][0] MISS, hämta block till rad 0
4.  Adress: ... 0000 0000 0100, Läs   a[1][0]   MISS, hämta block till rad 0
5.  Adress: ... 0100 0000 0100, Läs   b[1][0]   HIT, läs från rad 128
6.  Adress: ... 1000 0000 0100, Skriv res[1][0] MISS, hämta block till rad 0
7.  Adress: ... 0000 0000 1000, Läs   a[2][0]   MISS, hämta block till rad 1
8.  Adress: ... 0100 0000 1000, Läs   b[2][0]   MISS, hämta block till rad 129
9.  Adress: ... 1000 0000 1000, Skriv res[2][0] MISS, hämta block till rad 1
10  Adress: ... 0000 0000 1100, Läs   a[3][0]   MISS, hämta block till rad 1
12. Adress: ... 0100 0000 1100, Läs   b[3][0]   HIT, läs från rad 129
13. Adress: ... 1000 0000 1100, Skriv res[3][0] MISS, hämta block till rad 1
14. Adress: ... 0000 0001 0000, Läs   a[4][0]   MISS, hämta block till rad 2
15. Adress: ... 0100 0001 0000, Läs   b[4][0]   MISS, hämta block till rad 130
16. Adress: ... 1000 0001 0000, Skriv res[4][0] MISS, hämta block till rad 2
17. Adress: ... 0000 0001 0100, Läs   a[5][0]   MISS, hämta block till rad 2
18. Adress: ... 0100 0001 0100, Läs   b[5][0]   HIT, läs från rad 130
19. Adress: ... 1000 0001 0100, Skriv res[5][0] MISS, hämta block till rad 2

Om vi ökar cachens storlek till 2048 byte så kommer vi dock att behöva fler
indexbitar för att hålla reda på alla rader, vilket medför att a[i][j] och
b[i][j] får olika radindex. Tyvärr kommer a[i][j] och res[i][j] fortfarande
dela radindex. Vi ser i tabellen ovan att 1 av 6 operationer ger träff i
cachen, vilket ger oss en hit rate på ungefär 17%.

Cachestorlek 4096 byte.
1.  Adress: ... 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0
2.  Adress: ... 0100 0000 0000, Läs   b[0][0]   MISS, hämta block till rad 128
3.  Adress: ... 1000 0000 0000, Skriv res[0][0] MISS, hämta block till rad 256
4.  Adress: ... 0000 0000 0100, Läs   a[1][0]   HIT, läs från rad 0
5.  Adress: ... 0100 0000 0100, Läs   b[1][0]   HIT, läs från rad 128
6.  Adress: ... 1000 0000 0100, Skriv res[1][0] HIT, läs från rad 256

Om vi ökar cachens storlek ytterligare till 4096 byte så kommer vi få ännu
bättre hit rate. Nu kommer läsning av a[i][j] hamna på rad 0-127, läsning av
b[i][j] hama på rad 128-255 och skrivning till res hamna på rad 256-511.
Mönstret i tabellen kommer fortsätta vilket ger oss en hit rate på 50%.

5.6
Se 5.5.

5.8
Storlek: 512 byte.
Blockstorlek: 16 byte.
Rutstorlek: 512 / 4 = 128 byte.
Icke-tag: 7 bitar, eftersom 128 = 2^7.
Byte-offset: 4, eftersom 16 = 2^4.
Index: 3 bitar, eftersom 7 - 4 = 3.
Tag: 25 bitar, eftersom 32 - 7 = 25.
Rader: 8 rader, eftersom 2^3 = 8.

Validbitar finns i varje block, men dessa ritades inte ut på grund av
platsbrist.

BO: Byte-offset
I: Index

--------------- --------------- --------------- ---------------
|Tag     |I|BO| |Tag     |I|BO| |Tag     |I|BO| |Tag     |I|BO| x 8 rader
|25 bitar|3|4 | |25 bitar|3|4 | |25 bitar|3|4 | |25 bitar|3|4 |
--------------- --------------- --------------- ---------------

5.9
Antag att a[0][0] ligger på minnesplats 0. Adresserna nedan är trunkerade till
endast icke-tag bitarna.
1. Adress: 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0, ruta 0
2. Adress: 0100 0000 0000, Läs   b[0][0]   MISS, hämta block till rad 0, ruta 1
3. Adress: 1000 0000 0000, Skriv res[0][0] MISS, hämta block till rad 0, ruta 2
4. Adress: 0000 0000 0100, Läs   a[1][0]   MISS, hämta block till rad 0, ruta 3
5. Adress: 0100 0000 0100, Läs   b[1][0]   MISS, hämta block till rad 0, ruta 0

Eftersom indexbitarna är orörda för alla operationer ovan kommer alla
operationer ovan använda samma rad i cachen. Det innebär att varje operation
kommer att vilja skriva på rad 0, och det enda som kan variera är vilken ruta
som ska användas. Eftersom vi bara har 4 rutor i cachen och vi använder LRU
kommer den femte operationen skriva över det som den första operationen skrev
till cachen.

Svar: b[1][0] skriver över a[0][0].

5.10
För associativitetstal 1 är anledningen att varje cachmiss kommer att orsaka en
överskrivning av det föregående som skrevs/laddning till cachen. Se 5.5 för
detaljer; den ända skillnaden är att vi har större blockstorlek, men det
hjälper tyvärr inte. 

Situationen är nästan identisk med associativitetstal 4. Efter den fjärde
operationen kommer samtliga operationer att skriva över något i cachen. Se 5.9
för detaljer.

5.11
Byte-offset: 3 bitar, eftersom 8 = 2^3.

Storlek    | 64 | 128 | 256 | 512 | 1024 | 2048 | 4096 |
Indexbitar |  3 |   4 |   5 |   6 |    7 |    8 |    9 |

Antag att a[0][0] ligger på adress 0. Adresserna är trunkerade till endast
icke-tag bitarna.

Cachestorlekar 64 till 1024 byte. 
1. Adress: 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0
2. Adress: 0100 0000 0000, Läs   b[0][0]   MISS, hämta block till rad 0
3. Adress: 1000 0000 0000, Skriv res[0][0] MISS, hämta block till rad 0
4. Adress: 0000 0000 0001, Läs   a[0][1]   MISS, hämta block till rad 0
5. Adress: 0100 0000 0001, Läs   b[0][1]   MISS, hämta block till rad 0
6. Adress: 1000 0000 0001, Skriv res[0][1] MISS, hämta block till rad 0

Cachestorlek 2048. 
1. Adress: 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0
2. Adress: 0100 0000 0000, Läs   b[0][0]   MISS, hämta block till rad 128
3. Adress: 1000 0000 0000, Skriv res[0][0] MISS, hämta block till rad 0
4. Adress: 0000 0000 0001, Läs   a[0][1]   MISS, hämta block till rad 0
5. Adress: 0100 0000 0001, Läs   b[0][1]   HIT, läs från rad 128
6. Adress: 1000 0000 0001, Skriv res[0][1] MISS, hämta block till rad 0

Cachestorlek 4096 byte.
1.  Adress: ... 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0
2.  Adress: ... 0100 0000 0000, Läs   b[0][0]   MISS, hämta block till rad 128
3.  Adress: ... 1000 0000 0000, Skriv res[0][0] MISS, hämta block till rad 256
4.  Adress: ... 0000 0000 0001, Läs   a[1][0]   HIT, läs från rad 0
5.  Adress: ... 0100 0000 0001, Läs   b[1][0]   HIT, läs från rad 128
6.  Adress: ... 1000 0000 0001, Skriv res[1][0] HIT, läs från rad 256

Situationen är nästan identisk med 5.5/5.6.  Skillnaden är alla operationer
kommer fortsätta skriva på samma rader som tidigare istället för att öka
radnummer med 1 var sjätte operation.

5.12 
Samma förklaring som 5.5/5.6.

5.14
Storlek: 512 byte.
Rutstorlek: 128 byte, eftersom 512 / 4 = 128.
Blockstorlek: 16 byte.
Icke-tag: 7 bitar, eftersom 128 = 2^7.
Byte-offset: 4 bitar, eftersom 16 = 2^4.
Index: 3 bitar, eftersom 7 - 4 = 3.
Rader: 8 rader, eftersom 2^3 = 8.
Tag: 25 bitar, eftersom 32 - 7 = 25.

--------------- --------------- --------------- ---------------
|Tag     |I|BO| |Tag     |I|BO| |Tag     |I|BO| |Tag     |I|BO| x 8 rader
|25 bitar|3|4 | |25 bitar|3|4 | |25 bitar|3|4 | |25 bitar|3|4 |
--------------- --------------- --------------- ---------------

5.15
Antag att a[0][0] ligger på adress 0.
                  I   B
1.  Adress: 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0, ruta 0.
2.  Adress: 0100 0000 0000, Läs   b[0][0]   MISS, hämta block till rad 0, ruta 1.
3.  Adress: 1000 0000 0000, Skriv res[0][0] MISS, hämta block till rad 0, ruta 2.
4.  Adress: 0000 0000 0001, Läs   a[0][1]   HIT, läs från rad 0, ruta 0, ord 1.
5.  Adress: 0100 0000 0001, Läs   b[0][1]   HIT, läs från rad 0, ruta 1, ord 1.
6.  Adress: 1000 0000 0001, Skriv res[0][1] HIT, läs från rad 0, ruta 2, ord 1.
7.  Adress: 0000 0000 0010, Läs   a[0][2]   HIT, läs från rad 0, ruta 0, ord 2.
8.  Adress: 0100 0000 0010, Läs   b[0][2]   HIT, läs från rad 0, ruta 1, ord 2.
9.  Adress: 1000 0000 0010, Skriv res[0][2] HIT, läs från rad 0, ruta 2, ord 2.
10. Adress: 0000 0000 0011, Läs   a[0][3]   HIT, läs från rad 0, ruta 0, ord 3.
11. Adress: 0100 0000 0011, Läs   b[0][3]   HIT, läs från rad 0, ruta 1, ord 3.
12. Adress: 1000 0000 0011, Skriv res[0][3] HIT, läs från rad 0, ruta 2, ord 3.
13. Adress: 0000 0000 0100, Läs   a[0][4]   MISS, hämta block till rad 0, ruta 3.
14. Adress: 0100 0000 0100, Läs   b[0][4]   MISS, hämta block till rad 0, ruta 0.
15. Adress: 1000 0000 0100, Skriv res[0][4] MISS, hämta block till rad 0, ruta 1.

Svar: b[0][4] skriver över a[0][0].

5.16
Cacheminnet med associativitet 4 förklarades i uppgift 5.15. Se tabellen där för detaljer.

Associativitet 1
Storlek: 512 byte.
Rutstorlek: 512 byte.
Blockstorlek: 16 byte.
Icke-tag: 9 bitar, eftersom 512 = 2^9.
Byte-offset: 4 bitar, eftersom 16 = 2^4.
Index: 5 bitar, eftersom 9 - 4 = 5.
Rader: 32 rader, eftersom 2^5 = 32.
Tag: 23 bitar, eftersom 32 - 9 = 23.

---------------
|Tag     |I|BO| x 32 rader
|23 bitar|5|4 |
---------------

1. Adress: 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0.
2. Adress: 0100 0000 0000, Läs   b[0][0]   MISS, hämta block till rad 0.
3. Adress: 1000 0000 0000, Skriv res[0][0] MISS, hämta block till rad 0.
4. ...

Varje cachemiss skriver över det senaste som skrevs till cachen.

Associativitet 2
Storlek: 512 byte.
Rutstorlek: 256 byte.
Blockstorlek: 16 byte.
Icke-tag: 8 bitar, eftersom 256 = 2^8.
Byte-offset: 4 bitar, eftersom 16 = 2^4.
Index: 4 bitar, eftersom 8 - 4 = 4.
Rader: 16 rader, eftersom 2^4 = 16.
Tag: 24 rader, eftersom 32 - 8 = 24.

--------------- ---------------
|Tag     |I|BO| |Tag     |I|BO| x 16 rader
|24 bitar|4|4 | |24 bitar|4|4 |
--------------- ---------------

1. Adress: 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0, ruta 0.
2. Adress: 0100 0000 0000, Läs   b[0][0]   MISS, hämta block till rad 0, ruta 1.
3. Adress: 1000 0000 0000, Skriv res[0][0] MISS, hämta block till rad 0, ruta 0.
4. Adress: 0000 0000 0001, Läs   a[0][1]   MISS, hämta block till rad 0, ruta 1.

Varje cachemiss skriver över det näst senast som skrevs till cachen.

5.17
Storlek: 128 byte.
Rutstorlek: 32 byte.
Blockstorlek: 32 byte.
Icke-tag: 5 bitar, eftersom 32 = 2^5.
Byte-offset: 5 bitar, eftersom 32 = 2^5.
Index: 0 bitar.
Rader: 1 rad.
Tag: 27 bitar, eftersom 32 - 5 = 27.

------------- ------------- ------------- -------------
|Tag     |BO| |Tag     |BO| |Tag     |BO| |Tag     |BO|
|27 bitar|5 | |27 bitar|5 | |27 bitar|5 | |27 bitar|5 |
------------- ------------- ------------- -------------

5.18
Eftersom vi aldrig läser mer från något block än något annat så kommer LRU
alltid motsvara FIFO. Om vi istället hade läst exempelvis a[i][j] två gånger
hade utbytespolicyn spelat större roll gånger hade utbytespolicyn spelat större
roll.

5.19
Vi ser i tabellen nedan att av 24 instruktioner kommer 21 att vara
cacheträffar. Därför blir hit rate 21/24 = 0.875 <=> ~87%. Vi kan alltså
förvänta oss detta varje körning av detta program med denna cache.

1.  Adress: 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till ruta 0.
2.  Adress: 0100 0000 0000, Läs   b[0][0]   MISS, hämta block till ruta 1.
3.  Adress: 1000 0000 0000, Skriv res[0][0] MISS, hämta block till ruta 2.
4.  Adress: 0000 0000 0001, Läs   a[0][1]   HIT, läs från ruta 0, ord 1.
5.  Adress: 0100 0000 0001, Läs   b[0][1]   HIT, läs från ruta 1, ord 1.
6.  Adress: 1000 0000 0001, Skriv res[0][1] HIT, läs från ruta 2, ord 1.
7.  Adress: 0000 0000 0010, Läs   a[0][2]   HIT, läs från ruta 0, ord 2.
8.  Adress: 0100 0000 0010, Läs   b[0][2]   HIT, läs från ruta 1, ord 2.
9.  Adress: 1000 0000 0010, Skriv res[0][2] HIT, läs från ruta 2, ord 2.
10. Adress: 0000 0000 0011, Läs   a[0][3]   HIT, läs från ruta 0, ord 3.
11. Adress: 0100 0000 0011, Läs   b[0][3]   HIT, läs från ruta 1, ord 3.
12. Adress: 1000 0000 0011, Skriv res[0][3] HIT, läs från ruta 2, ord 3.
13. Adress: 0000 0000 0100, Läs   a[0][4]   HIT, läs från ruta 0, ord 4.
14. Adress: 0100 0000 0100, Läs   b[0][4]   HIT, läs från ruta 1, ord 4.
15. Adress: 1000 0000 0100, Skriv res[0][4] HIT, läs från ruta 2, ord 4.
16. Adress:      ...      , Läs   a[0][5]   HIT, läs från ruta 0, ord 5.
17. Adress:      ...      , Läs   b[0][5]   HIT, läs från ruta 1, ord 5.
18. Adress:      ...      , Skriv res[0][5] HIT, läs från ruta 2, ord 5.
19. Adress:      ...      , Läs   a[0][6]   HIT, läs från ruta 0, ord 6.
20. Adress:      ...      , Läs   b[0][6]   HIT, läs från ruta 1, ord 6.
21. Adress:      ...      , Skriv res[0][6] HIT, läs från ruta 2, ord 6.
22. Adress:      ...      , Läs   a[0][7]   HIT, läs från ruta 0, ord 7.
23. Adress:      ...      , Läs   b[0][7]   HIT, läs från ruta 1, ord 7.
24. Adress:      ...      , Skriv res[0][7] HIT, läs från ruta 2, ord 7.
25. Adress:      ...      , Läs   a[0][8]   MISS, hämta block till ruta 3.
26. Adress:      ...      , Läs   b[0][8]   MISS, hämta block till ruta 0.
27. Adress:      ...      , Skriv res[0][8] MISS, hämta block till ruta 1.

5.20
När vi ökar MATRIXSIZE_ROWS till 17 kommer vi få 16 nya matriselement per
matrix. Eftersom vi har 3 matriser kommer vi alltså att få 48 nya
matriselement. 

De nya elementen kommer att placeras mellan matriserna. 

5.21
Tidigare har vi räknat med att vi har haft 1024 byte mellan a[i][j] & b[i][j]
och b[i][j] & res[i][j]. Det kommer inte längre stämma. Vi har 16 nya
matriselement per matris. Det innebär att avståndet mellan a[i][j] och b[i][j]
kommer bli 1024 + 16 * 4 = 1088. Detsamma gäller avståndet mellan b[i][j] och
res[i][j]. Förhoppningsvis kommer detta leda till att a[i][j], b[i][j], och
res[i][j] inte längre delar index och vi slipper öka associativiteten för att
få effektiva cacheminnen.

5.22
Storlek: 64 byte.
Blockstorlek: 8 byte.
Icke-tag: 6 bitar, eftersom 64 = 2^6.
Byte-offset: 3 bitar, eftersom 8 = 2^3.
Index: 3 bitar, eftersom 6 - 3 = 3.
Rader: 8 rader, eftersom 2^3 = 8.
Tag: 26 bitar, eftersom 32 - 6 = 26.

                   I   B
1.  Adress: 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0.
2.  Adress: 0100 0100 0000, Läs   b[0][0]   MISS, hämta block till rad 0.
3.  Adress: 1000 0100 0000, Skriv res[0][0] MISS, hämta block till rad 0.

Varje cachemiss skriver över det som senast skrevs till cachen.

Storlek: 128 byte.
Blockstorlek: 8 byte.
Icke-tag: 7 bitar, eftersom 64 = 2^7.
Byte-offset: 3 bitar, eftersom 8 = 2^3.
Index: 4 bitar, eftersom 7 - 3 = 4.
Rader: 16 rader, eftersom 2^4 = 16.
Tag: 25 bitar, eftersom 32 - 7 = 25.
                  I    B
1.  Adress: 0000 0000 0000, Läs   a[0][0]   MISS, hämta block till rad 0.
2.  Adress: 0100 0100 0000, Läs   b[0][0]   MISS, hämta block till rad 1.
3.  Adress: 1000 1000 0000, Skriv res[0][0] MISS, hämta block till rad 0.
4.  Adress: 0000 0000 0001, Läs   a[0][0]   MISS, hämta block till rad 0.
5.  Adress: 0100 0100 0001, Läs   b[0][0]   HIT, läs från rad 1.
6.  Adress: 1000 1000 0001, Skriv res[0][0] MISS, hämta block till rad 0.

Lite bättre än förra cacheminnet, men a[i][j] och res[i][j] skriver fortfarande
över varandra. 1 av 6 ger hit.

Storlek: 256 - 4096 byte.
Nu kommer a[i][j], b[i][j] samt res[i][j] få varsin rad i cacheminnet. Eftersom
blockstorleken är 2 ord kommer varannan iteration i loopen ge hit.

5.23
Varje cachemiss skriver över det som senast skrevs till cachen. Se 5.22 för
detaljer.

5.25
Eftersom a[i][j], b[i][j] samt res[i][j] har varsin rad i cacheminnet spelar
associativiteten inte längre någon roll för hit rate.

5.26
Blockstorlek: 4 byte.
Eftersom varje block rymmer en int kommer vi bara att få cachemissar.

Blockstorlek: 8 byte.
Nu kommer varannan iteration av loopen att ge cacheträff. Se 5.22 för detaljer.

Blockstorlek: 16 byte.
Nu rymmer ett block 4 ints. Därför kommer 9 av 12 instruktioner ge cacheträff.
9 / 12 = 3 / 4 <=> 75%. 

Blockstorlek: 32 byte.
Nu rymmer ett block 8 ints. Därför kommer 21 av 24 instruktioner ge cacheträff.  
21 / 24 = 7 / 8 <=> ~85%.
